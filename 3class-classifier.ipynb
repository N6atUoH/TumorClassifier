{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12401046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms,models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from cnn_finetune import make_model\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5bc5d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#GPU指定\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# EfficientNet-b0 model のロード\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=2)\n",
    "#ファインチューニング（全てのパラメータを訓練可能に）\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True  \n",
    "model = model.to(device)\n",
    "\n",
    "#モデルの構造確認\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724fca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#データセットの設定\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='/home/yamaguchi/最終/Ki67値クラス分類データセット/train')  \n",
    "test_dataset  = torchvision.datasets.ImageFolder(root='/home/yamaguchi/最終/Ki67値クラス分類データセット/test') \n",
    "\n",
    "\n",
    "#学習用データの前処理\n",
    "transform = torchvision.transforms.Compose([\n",
    "    #ランダムな領域を切り取って画像をリサイズ\n",
    "    transforms.RandomCrop((224,224)),\n",
    "    # ランダムに画像を水平方向に反転\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # ランダムに画像の色調（明るさ，コントラスト）を変更\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    # グレースケールに変換（3チャンネル出力）\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    #ピクセル値の正規化\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "#テスト用データの前処理\n",
    "transform_2 = torchvision.transforms.Compose([\n",
    "    transforms.RandomCrop((224,224)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "#バッチサイズの設定(2の乗数が一般的)\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset.transform=transform\n",
    "test_dataset.transform=transform_2\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "\n",
    "#フォルダのクラス名の表示\n",
    "print(train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0fe393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルのパラメータ数などの確認\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3, 224, 224))\n",
    "\n",
    "#https://discuss.pytorch.org/t/what-is-1-in-output-shape-of-a-model-in-torch-summary/67790"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d1164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device, model, optimizer, criterion, cv_train_dataloader, cv_valid_dataloader):\n",
    "    # Early stoppingのための初期設定\n",
    "    the_last_loss = 100  # 監視する損失の初期値\n",
    "    patience = 10  # 許容できる損失の増加（非改善）のエポック数\n",
    "    trigger_times = 0  # 現在の非改善のエポック数\n",
    "\n",
    "    for epoch in range(100):  # 最大エポック数\n",
    "        model.train()  # モデルを訓練モードに設定\n",
    "        running_loss = 0.0  # 現在のエポックの累積損失\n",
    "        correct_num = 0  # 正しく予測されたデータの数\n",
    "        total_num = 0  # 総データ数\n",
    "        batch_count = 0  # 処理したバッチの数\n",
    "\n",
    "        for data, target in cv_train_dataloader:  # 訓練データのバッチごとのループ\n",
    "            inputs, labels = data.to(device), target.to(device)  # データをデバイスに移動\n",
    "\n",
    "            optimizer.zero_grad()  # 勾配をゼロに初期化\n",
    "\n",
    "            outputs = model(inputs)  # モデルによる予測\n",
    "            \n",
    "            loss = criterion(outputs, labels)  # 損失の計算\n",
    "            predicted = torch.max(outputs.data, 1)[1]  # 予測ラベル\n",
    "            correct_num_temp = (predicted == labels).sum()  # 正解数の計算\n",
    "            correct_num += correct_num_temp.item()\n",
    "            total_num += data.shape[0]\n",
    "            loss.backward()  # 損失に基づく勾配の計算\n",
    "            optimizer.step()  # パラメータの更新\n",
    "            running_loss += loss.item()\n",
    "            batch_count += 1 \n",
    "\n",
    "        # エポックごとの損失と正解率の表示\n",
    "        print('epoch:%d loss: %.3f acc: %.3f' %\n",
    "             (epoch + 1, running_loss / batch_count, correct_num * 100 / total_num))\n",
    "            \n",
    "\n",
    "        # 検証セットでの損失の計算（Early Stoppingのため）\n",
    "        the_current_loss = validation(model, device, cv_valid_dataloader, criterion)\n",
    "        print('The current loss:', the_current_loss)\n",
    "\n",
    "        # Early Stoppingの条件判定\n",
    "        if the_current_loss > the_last_loss:\n",
    "            trigger_times += 1\n",
    "            print('trigger times:', trigger_times)\n",
    "\n",
    "            if trigger_times >= patience:  # patience回連続で損失が改善しなかった場合\n",
    "                print('Early stopping!\\nStart to test process.')\n",
    "                return model\n",
    "\n",
    "        else:\n",
    "            print('trigger times: 0')\n",
    "            trigger_times = 0  # 損失が改善された場合、カウンタをリセット\n",
    "\n",
    "        the_last_loss = the_current_loss  # 監視する損失の更新\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3e1820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#検証関数の定義\n",
    "\n",
    "\n",
    "def validation(model, device, cv_valid_dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data,target in cv_valid_dataloader:\n",
    "            inputs, labels = data.to(device), target.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(cv_valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b762363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト関数の定義\n",
    "def test(device, model, test_dataloader):\n",
    "    model.eval()  # モデルを評価モードに設定\n",
    "\n",
    "    correct_num = 0  # 正解数\n",
    "    total_num = 0    # 総サンプル数\n",
    "    predicts_list = []  # 予測結果を格納するリスト\n",
    "    labels_list = []    # 実際のラベルを格納するリスト\n",
    "    scores_list = []    # 各クラスの確率を格納するリスト\n",
    "\n",
    "    with torch.no_grad():  # 勾配計算を無効化\n",
    "        for data, target in test_dataloader:\n",
    "            inputs, labels = data.to(device), target.to(device)  # データをデバイスに移動\n",
    "\n",
    "            outputs = model(inputs)  # モデルで予測\n",
    "            m = nn.Softmax(dim=1)  # Softmaxを適用して確率を計算\n",
    "            probs = m(outputs)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)  # 最も高い確率を持つクラスを予測値とする\n",
    "            correct_num_temp = (predicted == labels).sum()  # 正解数を計算\n",
    "            correct_num += correct_num_temp.item()\n",
    "            total_num += data.shape[0]\n",
    "\n",
    "            # CPUにデータを移動してnumpy配列に変換\n",
    "            labels = labels.to('cpu').numpy()\n",
    "            predicted = predicted.to('cpu').numpy()\n",
    "            probs = probs.to('cpu').numpy()\n",
    "\n",
    "            # リストに追加\n",
    "            labels_list.append(labels)\n",
    "            predicts_list.append(predicted)\n",
    "            scores_list.append(probs)\n",
    "\n",
    "    # リストをnumpy配列に変換\n",
    "    labels = np.concatenate(labels_list)\n",
    "    predicted = np.concatenate(predicts_list)\n",
    "    scores = np.concatenate(scores_list)\n",
    "\n",
    "    # ROC曲線とAUCの計算\n",
    "    labels_bin = label_binarize(labels, classes=[0, 1, 2])  # ラベルを二値化\n",
    "    fpr, tpr, roc_auc = {}, {}, {}\n",
    "    for i in range(3):\n",
    "        fpr[i], tpr[i], _ = roc_curve(labels_bin[:, i], scores[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # 混同行列とその他の指標を計算\n",
    "    C = confusion_matrix(labels, predicted)\n",
    "    ac = accuracy_score(labels, predicted)\n",
    "    pre = precision_score(labels, predicted, average='macro')\n",
    "    re = recall_score(labels, predicted, average='macro')\n",
    "    f1 = f1_score(labels, predicted, average='macro')\n",
    "    AUC = roc_auc_score(labels, scores, multi_class='ovr')  # AUCを計算\n",
    "\n",
    "    # 結果を表示\n",
    "    print(C)\n",
    "    print(\"\\n\")\n",
    "    print(\"test accuracy : %.3f\" % ac)\n",
    "    print(\"test precision : %.3f\" % pre)\n",
    "    print(\"test recall : %.3f\" % re)\n",
    "    print(\"test F1 : %.3f\" % f1)\n",
    "    print(\"AUC : %.3f\" % AUC)\n",
    "\n",
    "    for i in range(3):\n",
    "        print(\"AUC for class {}: {:.3f}\".format(i, roc_auc[i]))\n",
    "\n",
    "    # マクロ平均ROC曲線とAUCの計算とプロット\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(3)]))\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(3):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "    mean_tpr /= 3\n",
    "\n",
    "    fpr_macro, tpr_macro, roc_auc_macro = all_fpr, mean_tpr, auc(all_fpr, mean_tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr_macro, tpr_macro, label='macro-average ROC curve (area = {:.3g})'.format(roc_auc_macro),\n",
    "             color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    # クラスごとのROC曲線をプロット\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "    class_labels = ['class 0', 'class 1', 'class 2']\n",
    "    for i, color in zip(range(3), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2, label='ROC curve of class {0} (area = {1:.2f})'.format(class_labels[i], roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Extension of Receiver operating characteristic to multi-class')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    # 混同行列をプロット\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(C, annot=True, cmap='Blues', fmt='g', xticklabels=class_labels, yticklabels=class_labels, annot_kws={'size': 20})\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5909c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#k分割交差検証\n",
    "\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433dbc4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#プログラムの実行時間の算出\n",
    "%%time\n",
    "\n",
    "\n",
    "#main関数\n",
    "def main():\n",
    "    \n",
    "    for _fold, (train_index, valid_index) in enumerate(kf.split(np.arange(len(train_dataset)))):\n",
    "    \n",
    "        #交差検証に伴う使用モデルの再定義\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=3)\n",
    "       \n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True  \n",
    "        model = model.to(device)\n",
    "\n",
    "\n",
    "        batch_size = 32\n",
    "        #損失関数の定義\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        #最適化関数の定義\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.001,momentum=0.9)\n",
    "        \n",
    "        #交差検証に伴うデータセットの分割\n",
    "        cv_train_dataset = Subset(train_dataset, train_index)\n",
    "        cv_train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "        cv_valid_dataset   = Subset(train_dataset, valid_index)\n",
    "        cv_valid_dataloader = DataLoader(train_dataset, batch_size, shuffle=False)\n",
    "        \n",
    "        print('Fold {}------------------------------------------------------------------------------'.format(_fold+1))\n",
    "\n",
    "        model = train(device, model, optimizer, criterion, cv_train_dataloader, cv_valid_dataloader)\n",
    "        #パラメータの保存\n",
    "        torch.save(model.state_dict(), 'sample_' + str(_fold) + '.pt')\n",
    "        #test関数の実行\n",
    "        test(device, model, test_dataloader)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b91bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
