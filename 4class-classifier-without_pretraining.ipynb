{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12401046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms,models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from cnn_finetune import make_model\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5bc5d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = EfficientNet.from_name('efficientnet-b0')\n",
    "\n",
    "# 最終層の変更\n",
    "num_ftrs = model._fc.in_features\n",
    "model._fc = torch.nn.Linear(num_ftrs, 4)\n",
    "\n",
    "# すべての層をトレーニング可能に設定\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# モデルをデバイスに移動\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724fca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#データセットの設定\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='/home/yamaguchi/最終/GCB Non-GCB MALT Normal -最終/train')  #学習用データ：データ数は560\n",
    "test_dataset  = torchvision.datasets.ImageFolder(root='/home/yamaguchi/最終/GCB Non-GCB MALT Normal -最終/test') \n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    transforms.RandomCrop((224,224)),\n",
    "    # ランダムに画像を水平方向に反転\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # ランダムに画像の色調を変更\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    # グレースケールに変換（3チャンネル出力）\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "transform_2 = torchvision.transforms.Compose([\n",
    "    transforms.RandomCrop((224,224)),\n",
    "    # グレースケールに変換（3チャンネル出力）\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset.transform=transform\n",
    "test_dataset.transform=transform_2\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "\n",
    "print(train_dataset.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0fe393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3, 224, 224))\n",
    "\n",
    "#https://discuss.pytorch.org/t/what-is-1-in-output-shape-of-a-model-in-torch-summary/67790"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d1164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "def train(device, model, optimizer, criterion, cv_train_dataloader, cv_valid_dataloader):\n",
    "    # Early stoppingの設定\n",
    "    the_last_loss = 100  \n",
    "    patience = 10\n",
    "    trigger_times = 0\n",
    "\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_num = 0\n",
    "        total_num = 0\n",
    "        batch_count = 0\n",
    "\n",
    "        for data,target in  cv_train_dataloader:\n",
    "            inputs, labels = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            predicted = torch.max(outputs.data, 1)[1]\n",
    "            correct_num_temp = (predicted==labels).sum()\n",
    "            correct_num += correct_num_temp.item()\n",
    "            total_num += data.shape[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            batch_count += 1 \n",
    "\n",
    "        print('epoch:%d loss: %.3f acc: %.3f' %\n",
    "             (epoch + 1, running_loss / batch_count, correct_num*100/total_num))\n",
    "            \n",
    "\n",
    "        # Early stopping\n",
    "        the_current_loss = validation(model, device, cv_valid_dataloader, criterion)\n",
    "        print('The current loss:', the_current_loss)\n",
    "\n",
    "        if the_current_loss > the_last_loss:\n",
    "            trigger_times += 1\n",
    "            print('trigger times:', trigger_times)\n",
    "\n",
    "            if trigger_times >= patience:\n",
    "                print('Early stopping!\\nStart to test process.')\n",
    "                return model\n",
    "\n",
    "        else:\n",
    "            print('trigger times: 0')\n",
    "            trigger_times = 0\n",
    "\n",
    "        the_last_loss = the_current_loss\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3e1820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation\n",
    "\n",
    "def validation(model, device, cv_valid_dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data,target in cv_valid_dataloader:\n",
    "            inputs, labels = data.to(device), target.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(cv_valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b762363",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(device, model, test_dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "    predicts_list = []\n",
    "    labels_list = []\n",
    "    scores_list=[] \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            inputs, labels = data.to(device), target.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            m = nn.Softmax(dim=1)\n",
    "            probs = m(outputs)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct_num_temp = (predicted == labels).sum()\n",
    "            correct_num += correct_num_temp.item()\n",
    "            total_num += data.shape[0]\n",
    "\n",
    "            device2 = torch.device('cpu')\n",
    "            labels=labels.to(device2)\n",
    "            predicted = predicted.to(device2)\n",
    "            probs = probs.to(device2)\n",
    "\n",
    "            labels_list.append(labels)\n",
    "            predicts_list.append(predicted)\n",
    "            scores_list.append(probs)  \n",
    "    \n",
    "        labels = torch.cat(labels_list)\n",
    "        predicted = torch.cat(predicts_list)\n",
    "        scores = torch.cat(scores_list)  \n",
    "\n",
    "        labels_bin = label_binarize(labels, classes=[0, 1, 2, 3])  # Changed to four classes\n",
    "\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        for i in range(4):  # Changed loop range to four classes\n",
    "            fpr[i], tpr[i], _ = roc_curve(labels_bin[:, i], scores[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        C = confusion_matrix(labels, predicted)\n",
    "        ac = accuracy_score(labels, predicted)\n",
    "        pre = precision_score(labels, predicted, average='macro')\n",
    "        re = recall_score(labels, predicted, average='macro')\n",
    "        f1 = f1_score(labels, predicted, average='macro')\n",
    "\n",
    "        AUC = roc_auc_score(labels, scores, multi_class='ovr')  \n",
    "\n",
    "        print(C)\n",
    "        print(\"\\n\")\n",
    "        print(\"test accuracy : %.3f\" % ac)\n",
    "        print(\"test precison : %.3f\" % pre)\n",
    "        print(\"test recall : %.3f\" % re)\n",
    "        print(\"test f : %.3f\" % f1)\n",
    "        print(\"AUC : %.3f\" %(AUC))\n",
    "\n",
    "        for i in range(4):  # Changed loop range to four classes\n",
    "            print(\"AUC for class {}: {:.3f}\".format(i, roc_auc[i]))\n",
    "\n",
    "        # Compute macro-average ROC curve and ROC area\n",
    "        fpr_macro = dict()\n",
    "        tpr_macro = dict()\n",
    "        roc_auc_macro = dict()\n",
    "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(4)]))  # Changed loop range to four classes\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(4):  # Changed loop range to four classes\n",
    "            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "        mean_tpr /= 4  # Changed the denominator to four classes\n",
    "        fpr_macro[\"macro\"] = all_fpr\n",
    "        tpr_macro[\"macro\"] = mean_tpr\n",
    "        roc_auc_macro[\"macro\"] = auc(fpr_macro[\"macro\"], tpr_macro[\"macro\"])\n",
    "\n",
    "        # Plot all ROC curves\n",
    "        plt.figure()\n",
    "        plt.plot(fpr_macro[\"macro\"], tpr_macro[\"macro\"],\n",
    "                 label='macro-average ROC curve (area = {:.3g})'.format(roc_auc_macro[\"macro\"]),\n",
    "                 color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'red'])  # Added one more color for the additional class\n",
    "        class_labels = ['normal lymph nodes', 'MALToma', 'GCB', 'non-GCB']  # Changed to four class labels\n",
    "        for i, color in zip(range(4), colors):  # Changed loop range to four classes\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                     label='ROC curve of class {0} (area = {1:.3g})'\n",
    "                     ''.format(class_labels[i], roc_auc[i]))\n",
    "\n",
    "            \n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        \n",
    "        class_labels = ['normal lymph nodes', 'MALToma', 'GCB', 'non-GCB']   # Changed to four class labels\n",
    "        C = confusion_matrix(labels, predicted)\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(C, annot=True, cmap='Blues', fmt='g', xticklabels=class_labels, yticklabels=class_labels,annot_kws={'size': 20})\n",
    "        plt.xlabel('Predicted Labels')\n",
    "        plt.ylabel('True Labels')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "        plt.show()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5909c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#k分割交差検証\n",
    "\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433dbc4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def main():\n",
    "    \n",
    "    for _fold, (train_index, valid_index) in enumerate(kf.split(np.arange(len(train_dataset)))):\n",
    "    \n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # EfficientNet-b0 model のロード\n",
    "        model = EfficientNet.from_name('efficientnet-b0')\n",
    "\n",
    "        # 最終層の変更\n",
    "        num_ftrs = model._fc.in_features\n",
    "        model._fc = torch.nn.Linear(num_ftrs, 4)\n",
    "\n",
    "        # すべての層をトレーニング可能に設定\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # モデルをデバイスに移動\n",
    "        model = model.to(device)\n",
    "\n",
    "        batch_size = 32\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        # Pass all model parameters to the optimizer\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.001,momentum=0.9) # Optimize the entire model for fine-tuning\n",
    "        \n",
    "        cv_train_dataset = Subset(train_dataset, train_index)\n",
    "        cv_train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "        cv_valid_dataset   = Subset(train_dataset, valid_index)\n",
    "        cv_valid_dataloader = DataLoader(train_dataset, batch_size, shuffle=False)\n",
    "        \n",
    "        print('Fold {}------------------------------------------------------------------------------'.format(_fold+1))\n",
    "\n",
    "        model = train(device, model, optimizer, criterion, cv_train_dataloader, cv_valid_dataloader)\n",
    "        test(device, model, test_dataloader)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b91bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
